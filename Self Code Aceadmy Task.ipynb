{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Complete ML Pipeline For Self Code Aceadmy Assignment Task : Heart Disease Prediction\n",
        "============================================================\n",
        "Dataset: UCI Heart Disease Dataset (from Kaggle)\n",
        "Source: https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jkzjejll5kXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "print(\"ML TUTORIAL Assignment Task: Heart Disease Prediction\")\n",
        "print(\"Using Real Kaggle Dataset (UCI Heart Disease)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ggRvilD5sak",
        "outputId": "2fa08d13-f0e7-46ac-af4a-166f532c0086"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ML TUTORIAL Assignment Task: Heart Disease Prediction\n",
            "Using Real Kaggle Dataset (UCI Heart Disease)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"STEP 2: Loading Dataset from Kaggle\")\n",
        "\n",
        "try:\n",
        "    #  loading from UCI ML Repository\n",
        "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
        "\n",
        "    # Column names for the heart disease dataset\n",
        "    column_names = [\n",
        "        'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
        "        'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'\n",
        "    ]\n",
        "\n",
        "    df = pd.read_csv(url, names=column_names, na_values='?')\n",
        "    print(\"Dataset loaded from UCI Repository!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Could not load from URL: {e}\")\n",
        "    print(\"Creating dataset locally with sample data...\")\n",
        "\n",
        "    # Fallback: Create a representative sample of the heart disease dataset\n",
        "    # This is actual data structure from the UCI Heart Disease dataset\n",
        "    np.random.seed(42)\n",
        "    n_samples = 303  # Original dataset size\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'age': np.random.randint(29, 77, n_samples),\n",
        "        'sex': np.random.choice([0, 1], n_samples, p=[0.32, 0.68]),\n",
        "        'cp': np.random.choice([0, 1, 2, 3], n_samples, p=[0.47, 0.17, 0.28, 0.08]),\n",
        "        'trestbps': np.random.randint(94, 200, n_samples),\n",
        "        'chol': np.random.randint(126, 564, n_samples),\n",
        "        'fbs': np.random.choice([0, 1], n_samples, p=[0.85, 0.15]),\n",
        "        'restecg': np.random.choice([0, 1, 2], n_samples, p=[0.49, 0.49, 0.02]),\n",
        "        'thalach': np.random.randint(71, 202, n_samples),\n",
        "        'exang': np.random.choice([0, 1], n_samples, p=[0.67, 0.33]),\n",
        "        'oldpeak': np.round(np.random.uniform(0, 6.2, n_samples), 1),\n",
        "        'slope': np.random.choice([0, 1, 2], n_samples, p=[0.07, 0.46, 0.47]),\n",
        "        'ca': np.random.choice([0, 1, 2, 3], n_samples, p=[0.58, 0.22, 0.13, 0.07]),\n",
        "        'thal': np.random.choice([1, 2, 3], n_samples, p=[0.06, 0.55, 0.39]),\n",
        "        'target': np.random.choice([0, 1], n_samples, p=[0.46, 0.54])\n",
        "    })\n",
        "print(\"Sample dataset created!\")\n",
        "print(f\"Dataset Shape: {df.shape[0]} patients, {df.shape[1]} columns\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx7qmvXU54bv",
        "outputId": "fb1b372c-9813-4d98-955e-99ef2deb046a"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 2: Loading Dataset from Kaggle\n",
            "Dataset loaded from UCI Repository!\n",
            "Sample dataset created!\n",
            "Dataset Shape: 303 patients, 14 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 3: EXPLORE THE DATASET"
      ],
      "metadata": {
        "id": "lpn-0aXu8h53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nSTEP 3: Dataset Exploration\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "print(\"\\nFirst 10 rows of the dataset:\")\n",
        "print(df.head(10))\n",
        "\n",
        "print(\"\\nDataset Statistics:\")\n",
        "print(df.describe().round(2))\n",
        "\n",
        "print(\"\\nColumn Information:\")\n",
        "feature_descriptions = {\n",
        "    'age': 'Age in years',\n",
        "    'sex': 'Sex (1 = male, 0 = female)',\n",
        "    'cp': 'Chest pain type (0-3)',\n",
        "    'trestbps': 'Resting blood pressure (mm Hg)',\n",
        "    'chol': 'Serum cholesterol (mg/dl)',\n",
        "    'fbs': 'Fasting blood sugar > 120 mg/dl (1 = true, 0 = false)',\n",
        "    'restecg': 'Resting ECG results (0-2)',\n",
        "    'thalach': 'Maximum heart rate achieved',\n",
        "    'exang': 'Exercise induced angina (1 = yes, 0 = no)',\n",
        "    'oldpeak': 'ST depression induced by exercise',\n",
        "    'slope': 'Slope of peak exercise ST segment',\n",
        "    'ca': 'Number of major vessels (0-3)',\n",
        "    'thal': 'Thalassemia (1 = normal, 2 = fixed defect, 3 = reversible defect)',\n",
        "    'target': 'Heart Disease (1 = yes, 0 = no) - THIS IS WHAT WE PREDICT!'\n",
        "}\n",
        "\n",
        "for col, desc in feature_descriptions.items():\n",
        "    print(f\"  • {col}: {desc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PnqBYZn577s",
        "outputId": "6a557e44-a2a3-4c31-8061-e2887407aa64"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "STEP 3: Dataset Exploration\n",
            "--------------------------------------------------\n",
            "\n",
            "First 10 rows of the dataset:\n",
            "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
            "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
            "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
            "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
            "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
            "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
            "5  56.0  1.0  2.0     120.0  236.0  0.0      0.0    178.0    0.0      0.8   \n",
            "6  62.0  0.0  4.0     140.0  268.0  0.0      2.0    160.0    0.0      3.6   \n",
            "7  57.0  0.0  4.0     120.0  354.0  0.0      0.0    163.0    1.0      0.6   \n",
            "8  63.0  1.0  4.0     130.0  254.0  0.0      2.0    147.0    0.0      1.4   \n",
            "9  53.0  1.0  4.0     140.0  203.0  1.0      2.0    155.0    1.0      3.1   \n",
            "\n",
            "   slope   ca  thal  target  \n",
            "0    3.0  0.0   6.0       0  \n",
            "1    2.0  3.0   3.0       2  \n",
            "2    2.0  2.0   7.0       1  \n",
            "3    3.0  0.0   3.0       0  \n",
            "4    1.0  0.0   3.0       0  \n",
            "5    1.0  0.0   3.0       0  \n",
            "6    3.0  2.0   3.0       3  \n",
            "7    1.0  0.0   3.0       0  \n",
            "8    2.0  1.0   7.0       2  \n",
            "9    3.0  0.0   7.0       1  \n",
            "\n",
            "Dataset Statistics:\n",
            "          age     sex      cp  trestbps    chol     fbs  restecg  thalach  \\\n",
            "count  303.00  303.00  303.00    303.00  303.00  303.00   303.00   303.00   \n",
            "mean    54.44    0.68    3.16    131.69  246.69    0.15     0.99   149.61   \n",
            "std      9.04    0.47    0.96     17.60   51.78    0.36     0.99    22.88   \n",
            "min     29.00    0.00    1.00     94.00  126.00    0.00     0.00    71.00   \n",
            "25%     48.00    0.00    3.00    120.00  211.00    0.00     0.00   133.50   \n",
            "50%     56.00    1.00    3.00    130.00  241.00    0.00     1.00   153.00   \n",
            "75%     61.00    1.00    4.00    140.00  275.00    0.00     2.00   166.00   \n",
            "max     77.00    1.00    4.00    200.00  564.00    1.00     2.00   202.00   \n",
            "\n",
            "        exang  oldpeak   slope      ca    thal  target  \n",
            "count  303.00   303.00  303.00  299.00  301.00  303.00  \n",
            "mean     0.33     1.04    1.60    0.67    4.73    0.94  \n",
            "std      0.47     1.16    0.62    0.94    1.94    1.23  \n",
            "min      0.00     0.00    1.00    0.00    3.00    0.00  \n",
            "25%      0.00     0.00    1.00    0.00    3.00    0.00  \n",
            "50%      0.00     0.80    2.00    0.00    3.00    0.00  \n",
            "75%      1.00     1.60    2.00    1.00    7.00    2.00  \n",
            "max      1.00     6.20    3.00    3.00    7.00    4.00  \n",
            "\n",
            "Column Information:\n",
            "  • age: Age in years\n",
            "  • sex: Sex (1 = male, 0 = female)\n",
            "  • cp: Chest pain type (0-3)\n",
            "  • trestbps: Resting blood pressure (mm Hg)\n",
            "  • chol: Serum cholesterol (mg/dl)\n",
            "  • fbs: Fasting blood sugar > 120 mg/dl (1 = true, 0 = false)\n",
            "  • restecg: Resting ECG results (0-2)\n",
            "  • thalach: Maximum heart rate achieved\n",
            "  • exang: Exercise induced angina (1 = yes, 0 = no)\n",
            "  • oldpeak: ST depression induced by exercise\n",
            "  • slope: Slope of peak exercise ST segment\n",
            "  • ca: Number of major vessels (0-3)\n",
            "  • thal: Thalassemia (1 = normal, 2 = fixed defect, 3 = reversible defect)\n",
            "  • target: Heart Disease (1 = yes, 0 = no) - THIS IS WHAT WE PREDICT!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# STEP 4: DATA PREPROCESSING\n"
      ],
      "metadata": {
        "id": "M5H9lcKS8tbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"STEP 4: Data Preprocessing\")\n",
        "\n",
        "# Check for missing values\n",
        "missing = df.isnull().sum()\n",
        "print(f\"Missing Values:\")\n",
        "print(missing[missing > 0] if missing.sum() > 0 else \"  No missing values!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eURcGkAj5_YB",
        "outputId": "d7af8fb3-3ce6-4352-f32b-e029dfa84149"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 4: Data Preprocessing\n",
            "Missing Values:\n",
            "ca      4\n",
            "thal    2\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values if any\n",
        "if df.isnull().sum().sum() > 0:\n",
        "    print(\"\\n Handling missing values...\")\n",
        "    # Fill numeric columns with median\n",
        "    for col in df.columns:\n",
        "        if df[col].isnull().sum() > 0:\n",
        "            df[col].fillna(df[col].median(), inplace=True)\n",
        "    print(\"  Missing values filled with median \")\n",
        "\n",
        "# Check target distribution\n",
        "print(f\"\\nTarget Variable Distribution:\")\n",
        "target_counts = df['target'].value_counts()\n",
        "print(f\"No Heart Disease (0): {target_counts.get(0, 0)} patients ({target_counts.get(0, 0)/len(df)*100:.1f}%)\")\n",
        "print(f\"Heart Disease (1): {target_counts.get(1, 0)} patients ({target_counts.get(1, 0)/len(df)*100:.1f}%)\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzOPAvK19gRB",
        "outputId": "571b75a8-0472-4377-8d09-2bf0a94a266e"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Handling missing values...\n",
            "  Missing values filled with median \n",
            "\n",
            "Target Variable Distribution:\n",
            "No Heart Disease (0): 164 patients (54.1%)\n",
            "Heart Disease (1): 55 patients (18.2%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3136178923.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "print(\"Separating Features (X) and Target (y)...\")\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "\n",
        "# Convert target to int (handle any edge cases)\n",
        "y = y.astype(int)\n",
        "# Handle target values > 0 (in original dataset, values 1-4 all mean disease)\n",
        "y = (y > 0).astype(int)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpDYm9xs96ax",
        "outputId": "c01091bd-983b-4f1a-af8c-765be1ca0de8"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Separating Features (X) and Target (y)...\n",
            "Features shape: (303, 13)\n",
            "Target shape: (303,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "print(\"Splitting into Training (80%) and Testing (20%) sets...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y  # Maintain class balance\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Testing samples: {len(X_test)}\")\n",
        "\n",
        "# Feature scaling\n",
        "print(\"Scaling features (StandardScaler)...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "print(\"Features scaled to mean=0, std=1 \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-WBC4N1-A6G",
        "outputId": "4445f93a-8e40-47b7-8e03-2c2c015ccd39"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting into Training (80%) and Testing (20%) sets...\n",
            "Training samples: 242\n",
            "Testing samples: 61\n",
            "Scaling features (StandardScaler)...\n",
            "Features scaled to mean=0, std=1 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 5: MODEL TRAINING"
      ],
      "metadata": {
        "id": "eombO3nK-I0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n Model Training\")\n",
        "\n",
        "print(\"\\n Creating Logistic Regression model...\")\n",
        "model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "print(\" Training the model on patient data...\")\n",
        "model.fit(X_train_scaled, y_train)\n",
        "print(\" Model trained successfully!\")\n",
        "\n",
        "# Display learned coefficients\n",
        "print(\"\\n What the Model Learned (Feature Importance):\")\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Coefficient': model.coef_[0],\n",
        "    'Impact': ['↑ Increases Risk' if c > 0 else '↓ Decreases Risk' for c in model.coef_[0]]\n",
        "}).sort_values('Coefficient', key=abs, ascending=False)\n",
        "\n",
        "print(feature_importance.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBKYLAQz6Bun",
        "outputId": "ed1a2196-45b9-4c63-9e6f-7ebd36824fc6"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Model Training\n",
            "\n",
            " Creating Logistic Regression model...\n",
            " Training the model on patient data...\n",
            " Model trained successfully!\n",
            "\n",
            " What the Model Learned (Feature Importance):\n",
            " Feature  Coefficient           Impact\n",
            "      ca     1.107898 ↑ Increases Risk\n",
            "    thal     0.677821 ↑ Increases Risk\n",
            "     sex     0.655563 ↑ Increases Risk\n",
            "      cp     0.543483 ↑ Increases Risk\n",
            "   exang     0.383642 ↑ Increases Risk\n",
            "   slope     0.354072 ↑ Increases Risk\n",
            " thalach    -0.348486 ↓ Decreases Risk\n",
            "trestbps     0.313655 ↑ Increases Risk\n",
            "     fbs    -0.220560 ↓ Decreases Risk\n",
            " restecg     0.217329 ↑ Increases Risk\n",
            "    chol     0.215375 ↑ Increases Risk\n",
            " oldpeak     0.149953 ↑ Increases Risk\n",
            "     age    -0.103159 ↓ Decreases Risk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SUMMARY"
      ],
      "metadata": {
        "id": "WkK9ziN8-dA7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWrzucve4K97",
        "outputId": "1fe176ea-7e1b-4055-e8a5-17982004bfbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TUTORIAL COMPLETE!\n",
            "\n",
            " Model Performance Summary:\n",
            "   • Dataset: UCI Heart Disease (303 patients, 13 features)\n",
            "   • Algorithm: Logistic Regression\n",
            "   • Accuracy: 86.89%\n",
            "   • Training samples: 242\n",
            "   • Testing samples: 61\n",
            "\n",
            " What i have Learned:\n",
            "   • Loading real-world Kaggle datasets\n",
            "   • Exploratory Data Analysis (EDA)\n",
            "   • Data preprocessing (missing values, scaling)\n",
            "   • Train-test split with stratification\n",
            "   • Training Logistic Regression model\n",
            "   • Evaluating with confusion matrix & classification report\n",
            "   • Making predictions on new data\n",
            "\n",
            " Next Steps to try:\n",
            "   • Try Random Forest or XGBoost for better accuracy\n",
            "   • Perform hyperparameter tuning (GridSearchCV)\n",
            "   • Add more visualizations (ROC curve, feature correlations)\n",
            "   • Deploy as a web app with Streamlit or Flask\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\" TUTORIAL COMPLETE!\")\n",
        "print(f\"\"\"\n",
        " Model Performance Summary:\n",
        "   • Dataset: UCI Heart Disease (303 patients, 13 features)\n",
        "   • Algorithm: Logistic Regression\n",
        "   • Accuracy: {accuracy * 100:.2f}%\n",
        "   • Training samples: {len(X_train)}\n",
        "   • Testing samples: {len(X_test)}\n",
        "\n",
        " What i have Learned:\n",
        "   • Loading real-world Kaggle datasets\n",
        "   • Exploratory Data Analysis (EDA)\n",
        "   • Data preprocessing (missing values, scaling)\n",
        "   • Train-test split with stratification\n",
        "   • Training Logistic Regression model\n",
        "   • Evaluating with confusion matrix & classification report\n",
        "   • Making predictions on new data\n",
        "\n",
        " Next Steps to try:\n",
        "   • Try Random Forest or XGBoost for better accuracy\n",
        "   • Perform hyperparameter tuning (GridSearchCV)\n",
        "   • Add more visualizations (ROC curve, feature correlations)\n",
        "   • Deploy as a web app with Streamlit or Flask\n",
        "\"\"\")\n"
      ]
    }
  ]
}